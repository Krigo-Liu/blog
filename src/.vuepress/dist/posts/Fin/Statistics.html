<!doctype html>
<html lang="en-US" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.20" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.74" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://krigo-liu.github.io/blog/posts/Fin/Statistics.html"><meta property="og:site_name" content="Blog Demo"><meta property="og:title" content="Statistics"><meta property="og:description" content="Regression: OLS, GLM, logistic, and etc. Time-series : ARIMA, GARCH, ECM Nonparametric Regression: Splines, Kernel, Locally Weighted Regression Data exploration: Density, estima..."><meta property="og:type" content="article"><meta property="og:locale" content="en-US"><meta property="og:updated_time" content="2025-03-23T02:55:29.000Z"><meta property="article:author" content="Doris"><meta property="article:tag" content="Fin"><meta property="article:published_time" content="2024-08-01T00:00:00.000Z"><meta property="article:modified_time" content="2025-03-23T02:55:29.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"Statistics","image":[""],"datePublished":"2024-08-01T00:00:00.000Z","dateModified":"2025-03-23T02:55:29.000Z","author":[{"@type":"Person","name":"Doris"}]}</script><title>Statistics | Blog Demo</title><meta name="description" content="Regression: OLS, GLM, logistic, and etc. Time-series : ARIMA, GARCH, ECM Nonparametric Regression: Splines, Kernel, Locally Weighted Regression Data exploration: Density, estima...">
    <link rel="preload" href="/assets/style-B_SxluOH.css" as="style"><link rel="stylesheet" href="/assets/style-B_SxluOH.css">
    <link rel="modulepreload" href="/assets/app-HjLdIzEb.js"><link rel="modulepreload" href="/assets/Statistics.html-C3ffjxlJ.js"><link rel="modulepreload" href="/assets/plugin-vue_export-helper-DlAUqK2U.js">
    <link rel="prefetch" href="/assets/index.html-B7E56qE5.js" as="script"><link rel="prefetch" href="/assets/intro.html-FFVm1pZC.js" as="script"><link rel="prefetch" href="/assets/index.html-Cwl-s3_v.js" as="script"><link rel="prefetch" href="/assets/index.html-5F1IBfi5.js" as="script"><link rel="prefetch" href="/assets/intro.html-97lVpcdr.js" as="script"><link rel="prefetch" href="/assets/BF.html-B6fIGejf.js" as="script"><link rel="prefetch" href="/assets/BacktestEva.html-BDliJ34d.js" as="script"><link rel="prefetch" href="/assets/Direction.html-EieFgwUp.js" as="script"><link rel="prefetch" href="/assets/Finance.html-nvv_Abpq.js" as="script"><link rel="prefetch" href="/assets/Maths.html-C8a62nsI.js" as="script"><link rel="prefetch" href="/assets/qf formulas.html-DlONvR3o.js" as="script"><link rel="prefetch" href="/assets/HPC.html-B-hsc4E4.js" as="script"><link rel="prefetch" href="/assets/Learning_Makefile.html-BQE0AzA_.js" as="script"><link rel="prefetch" href="/assets/cmd.html-B0YstHeN.js" as="script"><link rel="prefetch" href="/assets/conda.html-BYzXM7_7.js" as="script"><link rel="prefetch" href="/assets/git.html-BCWu1XpS.js" as="script"><link rel="prefetch" href="/assets/linux.html-D4HNdrwG.js" as="script"><link rel="prefetch" href="/assets/styles.html-DD7EFDFs.js" as="script"><link rel="prefetch" href="/assets/Blog_conf.html-S1b40lqM.js" as="script"><link rel="prefetch" href="/assets/index.html-BQ6ploKX.js" as="script"><link rel="prefetch" href="/assets/disable.html-DLYgIheq.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-cV5d37M_.js" as="script"><link rel="prefetch" href="/assets/layout.html-BwkfOlHU.js" as="script"><link rel="prefetch" href="/assets/markdown.html-C3vhHJ02.js" as="script"><link rel="prefetch" href="/assets/page.html-BZtceW4n.js" as="script"><link rel="prefetch" href="/assets/cherry.html-BLYKrZVz.js" as="script"><link rel="prefetch" href="/assets/dragonfruit.html-fhjVwvVZ.js" as="script"><link rel="prefetch" href="/assets/strawberry.html-CXOjxKBS.js" as="script"><link rel="prefetch" href="/assets/tomato.html-BGhND3iw.js" as="script"><link rel="prefetch" href="/assets/Algorithms.html-CEnPLPOR.js" as="script"><link rel="prefetch" href="/assets/1 Introduction.html-BMtqueZp.js" as="script"><link rel="prefetch" href="/assets/10 Self-supervised learning.html-BxuHesxR.js" as="script"><link rel="prefetch" href="/assets/2 Image classification with linear classifiers.html-CxhvFVfl.js" as="script"><link rel="prefetch" href="/assets/3 CNN.html-CYnSHgAY.js" as="script"><link rel="prefetch" href="/assets/8 CNN Representation.html-PjzYylOa.js" as="script"><link rel="prefetch" href="/assets/9 Transformer.html-BzumONJ_.js" as="script"><link rel="prefetch" href="/assets/Formula.html-DoLPKZdI.js" as="script"><link rel="prefetch" href="/assets/SLDG_Introduction.html-UbaYaNpu.js" as="script"><link rel="prefetch" href="/assets/1.html-DHIR2bMh.js" as="script"><link rel="prefetch" href="/assets/2.html-rfLFCi9s.js" as="script"><link rel="prefetch" href="/assets/3.html-DpLV-0Zm.js" as="script"><link rel="prefetch" href="/assets/4.html-By6N6UdV.js" as="script"><link rel="prefetch" href="/assets/1.html-CgArr3rk.js" as="script"><link rel="prefetch" href="/assets/2.html-B0NTAVFZ.js" as="script"><link rel="prefetch" href="/assets/3.html-tGdWJ4z8.js" as="script"><link rel="prefetch" href="/assets/4.html-CCdfHLnI.js" as="script"><link rel="prefetch" href="/assets/404.html-BXwLFrB8.js" as="script"><link rel="prefetch" href="/assets/index.html-D18SXGLo.js" as="script"><link rel="prefetch" href="/assets/index.html-CVY7yJ8V.js" as="script"><link rel="prefetch" href="/assets/index.html-DoKthi5L.js" as="script"><link rel="prefetch" href="/assets/index.html-BsvbytfA.js" as="script"><link rel="prefetch" href="/assets/index.html-C01p2mZo.js" as="script"><link rel="prefetch" href="/assets/index.html-BkW3tvrG.js" as="script"><link rel="prefetch" href="/assets/index.html-BzpcjO93.js" as="script"><link rel="prefetch" href="/assets/index.html-Clssx0UC.js" as="script"><link rel="prefetch" href="/assets/index.html-C-7ci16t.js" as="script"><link rel="prefetch" href="/assets/index.html-NbOKObrH.js" as="script"><link rel="prefetch" href="/assets/index.html-pltGBeK_.js" as="script"><link rel="prefetch" href="/assets/index.html-CMyfDnOp.js" as="script"><link rel="prefetch" href="/assets/index.html-BWRtQCRm.js" as="script"><link rel="prefetch" href="/assets/index.html-DTPPwN8z.js" as="script"><link rel="prefetch" href="/assets/index.html-Cp_SoBfP.js" as="script"><link rel="prefetch" href="/assets/index.html-CdsS_tel.js" as="script"><link rel="prefetch" href="/assets/index.html-CiyWB6pm.js" as="script"><link rel="prefetch" href="/assets/index.html-D2UuoDRw.js" as="script"><link rel="prefetch" href="/assets/index.html-Cw1_Qi92.js" as="script"><link rel="prefetch" href="/assets/index.html-BKyPPbky.js" as="script"><link rel="prefetch" href="/assets/index.html-CVXzNs94.js" as="script"><link rel="prefetch" href="/assets/index.html-Dnpyf2Yn.js" as="script"><link rel="prefetch" href="/assets/index.html-cbvC1OF9.js" as="script"><link rel="prefetch" href="/assets/index.html-DBeRTxRf.js" as="script"><link rel="prefetch" href="/assets/index.html-abPaSV29.js" as="script"><link rel="prefetch" href="/assets/index.html-BhA5GLVf.js" as="script"><link rel="prefetch" href="/assets/index.html-BPnh3-Gn.js" as="script"><link rel="prefetch" href="/assets/index.html-B3XcQqgN.js" as="script"><link rel="prefetch" href="/assets/index.html-B51IHZCd.js" as="script"><link rel="prefetch" href="/assets/index.html-BCBH9ECq.js" as="script"><link rel="prefetch" href="/assets/index.html-WYQ7z8JW.js" as="script"><link rel="prefetch" href="/assets/index.html-l-DEnQjq.js" as="script"><link rel="prefetch" href="/assets/index.html-DzoLEgG-.js" as="script"><link rel="prefetch" href="/assets/index.html-78ZWyopi.js" as="script"><link rel="prefetch" href="/assets/index.html-Dqm3pAa-.js" as="script"><link rel="prefetch" href="/assets/index.html-_TyTnIgD.js" as="script"><link rel="prefetch" href="/assets/index.html-Cpa2jxp7.js" as="script"><link rel="prefetch" href="/assets/index.html-Ma37rRkO.js" as="script"><link rel="prefetch" href="/assets/index.html-DvTWj6i8.js" as="script"><link rel="prefetch" href="/assets/index.html-DD-v8vcI.js" as="script"><link rel="prefetch" href="/assets/index.html-CekweI-J.js" as="script"><link rel="prefetch" href="/assets/index.html-CaqTZOCk.js" as="script"><link rel="prefetch" href="/assets/index.html-D82jcplJ.js" as="script"><link rel="prefetch" href="/assets/index.html-B2XJKvO3.js" as="script"><link rel="prefetch" href="/assets/index.html-gA5OfPoW.js" as="script"><link rel="prefetch" href="/assets/index.html-BqRp-hNm.js" as="script"><link rel="prefetch" href="/assets/index.html-BNYRLccE.js" as="script"><link rel="prefetch" href="/assets/index.html-C62Y9RJV.js" as="script"><link rel="prefetch" href="/assets/index.html-DYjAkcRA.js" as="script"><link rel="prefetch" href="/assets/index.html-DnR6se95.js" as="script"><link rel="prefetch" href="/assets/index.html-B-mJh8GQ.js" as="script"><link rel="prefetch" href="/assets/index.html-Cc604P64.js" as="script"><link rel="prefetch" href="/assets/index.html-BH13ILGl.js" as="script"><link rel="prefetch" href="/assets/index.html-BvH2GF13.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-DXWKOczD.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">Skip to main content</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="Take me home"><img class="vp-nav-logo" src="https://theme-hope-assets.vuejs.press/logo.svg" alt><!----><span class="vp-site-name hide-in-pad">Blog Demo</span></a><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="博客主页" iconsizing="height"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:home" height="1em" sizing="height"></iconify-icon><!--]-->博客主页<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Posts"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:pen-to-square" height="1em" sizing="height"></iconify-icon>Posts<!--]--><span class="arrow"></span><ul class="vp-dropdown"></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="auto-link external-link" href="https://theme-hope.vuejs.press/" aria-label="V2 Docs" rel="noopener noreferrer" target="_blank" iconsizing="height"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:book" height="1em" sizing="height"></iconify-icon><!--]-->V2 Docs<!----></a></div></nav><!--]--></div><div class="vp-navbar-end"><!--[--><div class="vp-nav-item"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="Select language"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon i18n-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="i18n icon" name="i18n" style="width:1rem;height:1rem;vertical-align:middle;"><path d="M379.392 460.8 494.08 575.488l-42.496 102.4L307.2 532.48 138.24 701.44l-71.68-72.704L234.496 460.8l-45.056-45.056c-27.136-27.136-51.2-66.56-66.56-108.544h112.64c7.68 14.336 16.896 27.136 26.112 35.84l45.568 46.08 45.056-45.056C382.976 312.32 409.6 247.808 409.6 204.8H0V102.4h256V0h102.4v102.4h256v102.4H512c0 70.144-37.888 161.28-87.04 210.944L378.88 460.8zM576 870.4 512 1024H409.6l256-614.4H768l256 614.4H921.6l-64-153.6H576zM618.496 768h196.608L716.8 532.48 618.496 768z"></path></svg><!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/posts/Fin/Statistics.html" aria-label="English" iconsizing="both"><!---->English<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/zh/" aria-label="简体中文" iconsizing="both"><!---->简体中文<!----></a></li></ul></button></div></div><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!----><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="博客主页" iconsizing="both"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:home" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->博客主页<!----></a></li><li><section class="vp-sidebar-group"><p class="vp-sidebar-header active"><iconify-icon class="vp-icon" icon="fa6-solid:book" width="1em" height="1em" sizing="both"></iconify-icon><span class="vp-sidebar-title">Notes</span><!----></p><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/posts/" aria-label="Doris&#39;s branch" iconsizing="both"><!---->Doris&#39;s branch<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">AI</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">Fin</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/posts/Fin/Direction.html" aria-label="Direction" iconsizing="both"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->Direction<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/Fin/Finance.html" aria-label="Macroeconomics" iconsizing="both"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->Macroeconomics<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/Fin/Maths.html" aria-label="Maths" iconsizing="both"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->Maths<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/Fin/BF.html" aria-label="BFR-Microeconomics" iconsizing="both"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->BFR-Microeconomics<!----></a></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/posts/Fin/Statistics.html" aria-label="Statistics" iconsizing="both"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->Statistics<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/Fin/BacktestEva.html" aria-label="BacktestEva" iconsizing="both"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:file" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->BacktestEva<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/Fin/qf%20formulas.html" aria-label="/posts/Fin/qf%20formulas.html" iconsizing="both"><!---->/posts/Fin/qf%20formulas.html<!----></a></li></ul></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">MATH</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Others</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">博客制作</span><span class="vp-arrow end"></span></button><!----></section></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="介绍页" iconsizing="both"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:circle-info" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->介绍页<!----></a></li><li><a class="auto-link external-link vp-sidebar-link" href="https://ecosystem.vuejs.press/plugins/markdown/revealjs/demo.html" aria-label="Slides" rel="noopener noreferrer" target="_blank" iconsizing="both"><!--[--><iconify-icon class="vp-icon" icon="fa6-solid:person-chalkboard" width="1em" height="1em" sizing="both"></iconify-icon><!--]-->Slides<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><iconify-icon class="vp-icon" icon="fa6-solid:file" height="1em" sizing="height"></iconify-icon>Statistics</h1><div class="page-info"><span class="page-author-info" aria-label="Author🖊" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><span class="page-author-item">Doris</span></span><span property="author" content="Doris"></span></span><!----><span class="page-date-info" aria-label="Writing Date📅" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">July 31, 2024</span><meta property="datePublished" content="2024-08-01T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="Reading Time⌛" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>About 8 min</span><meta property="timeRequired" content="PT8M"></span><span class="page-category-info" aria-label="Category🌈" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon category-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="category icon" name="category"><path d="M148.41 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H148.41c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.311-40.31zM147.556 553.478H429.73c22.263 0 40.311 18.048 40.311 40.31v282.176c0 22.263-18.048 40.312-40.31 40.312H147.555c-22.263 0-40.311-18.049-40.311-40.312V593.79c0-22.263 18.048-40.311 40.31-40.311zM593.927 106.992h282.176c22.263 0 40.31 18.048 40.31 40.31V429.48c0 22.263-18.047 40.31-40.31 40.31H593.927c-22.263 0-40.311-18.047-40.311-40.31V147.302c0-22.263 18.048-40.31 40.31-40.31zM730.22 920.502H623.926c-40.925 0-74.22-33.388-74.22-74.425V623.992c0-41.038 33.387-74.424 74.425-74.424h222.085c41.038 0 74.424 33.226 74.424 74.067v114.233c0 10.244-8.304 18.548-18.547 18.548s-18.548-8.304-18.548-18.548V623.635c0-20.388-16.746-36.974-37.33-36.974H624.13c-20.585 0-37.331 16.747-37.331 37.33v222.086c0 20.585 16.654 37.331 37.126 37.331H730.22c10.243 0 18.547 8.304 18.547 18.547 0 10.244-8.304 18.547-18.547 18.547z"></path></svg><!--[--><span class="page-category-item color2 clickable" role="navigation">Fin</span><!--]--><meta property="articleSection" content="Fin"></span><span class="page-tag-info" aria-label="Tag🏷" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon tag-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="tag icon" name="tag"><path d="M939.902 458.563L910.17 144.567c-1.507-16.272-14.465-29.13-30.737-30.737L565.438 84.098h-.402c-3.215 0-5.726 1.005-7.634 2.913l-470.39 470.39a10.004 10.004 0 000 14.164l365.423 365.424c1.909 1.908 4.42 2.913 7.132 2.913s5.223-1.005 7.132-2.913l470.39-470.39c2.01-2.11 3.014-5.023 2.813-8.036zm-240.067-72.121c-35.458 0-64.286-28.828-64.286-64.286s28.828-64.285 64.286-64.285 64.286 28.828 64.286 64.285-28.829 64.286-64.286 64.286z"></path></svg><!--[--><span class="page-tag-item color2 clickable" role="navigation">Fin</span><!--]--><meta property="keywords" content="Fin"></span></div><hr></div><!----><!----><div class="theme-hope-content" vp-content><ol><li>Regression: OLS, GLM, logistic, and etc.</li><li>Time-series : ARIMA, GARCH, ECM</li><li>Nonparametric Regression: Splines, Kernel, Locally Weighted Regression</li><li>Data exploration: Density, estimation, normality, tests, monte carlo copulas</li><li>Data Cleaning and reduction: Cluster analysis, and stats theory</li></ol><h1 id="_1-regression" tabindex="-1"><a class="header-anchor" href="#_1-regression"><span>1 Regression</span></a></h1><h2 id="_1-1-linear-models" tabindex="-1"><a class="header-anchor" href="#_1-1-linear-models"><span>1.1 Linear models</span></a></h2><ol><li>linear model: coeffiecients $\beta$ are linear.</li></ol><h3 id="_1-1-2-simple-linear-regression-slr" tabindex="-1"><a class="header-anchor" href="#_1-1-2-simple-linear-regression-slr"><span>1.1.2 Simple linear regression(SLR)</span></a></h3><p>$$<br> y = \beta_0+\beta_1x+\epsilon_i<br> $$</p><p>where</p><ul><li>$\beta_0\text{ population intercept },\beta_1 \text{ population slope }$ are fixed but unknown. Estimated by $b_0\text{ and } b_1$ (whether using maximum likelihood or OLS, same result). $\beta_1$ means the amount of change in $E(y)$ when one unit change in x.</li><li>$(x_i, y_i)$ is a pair of data, plug in the formula: $y_i = \beta_0+\beta_1x_i+\epsilon_i$ . The only variable in this<br> formula is $\epsilon_i$.</li><li>$\epsilon$ is the model error, which follows the normal theory $\epsilon_i \sim N(0,\sigma^2)$. <ul><li><p>It is iid(independent identically distributed). $cov(\epsilon_i,\epsilon_j)=0, \text{for i} \neq j$.</p></li><li><p>Homogeneous variance assumption $var(\epsilon_i)=\sigma^2$. (note: the unbiased estimator of $\sigma$ is $s$)</p><p>$$<br> s<sup n="">2=\dfrac{1}{n-2}\sum\limits_{i=1}</sup>(y_i-\hat{y_i})^2<br> $$</p><p><strong>Some inferences</strong>:</p></li></ul></li></ul><ol><li>$E(a)=a$. $E(\epsilon_i)=0$<br> $$<br> E(y_i)=E(\beta_0+\beta_1+\epsilon_i)=E(\beta_0+\beta_1x_i)+E(\epsilon_i)=\beta_0+\beta_1x_i<br> $$</li><li>$var(a)=0$<br> $$<br> var(y_i)=var(\beta_0+\beta_1+\epsilon_i)=var(\beta_0+\beta_1x_i)+var(\epsilon_i)=\sigma^2<br> $$</li></ol><h3 id="_1-1-3-multiple-linear-regression-mlr" tabindex="-1"><a class="header-anchor" href="#_1-1-3-multiple-linear-regression-mlr"><span>1.1.3 Multiple linear regression (MLR)</span></a></h3><p>$$<br> \hat{y}=X\hat{\beta}+\hat{\epsilon}<br> $$</p><h3 id="_1-1-4-ordinary-least-squares-ols" tabindex="-1"><a class="header-anchor" href="#_1-1-4-ordinary-least-squares-ols"><span>1.1.4 Ordinary least squares (OLS)</span></a></h3><ol><li>A method to estimate unknown paras$\beta$. in a linear regression model.</li><li>It can be used in SLR &amp; MLR (&gt;1 regressor).</li></ol><h5 id="in-slr-2-paras-beta-0-beta-1-and-their-estimators-are-b-0-b-1-use-ols" tabindex="-1"><a class="header-anchor" href="#in-slr-2-paras-beta-0-beta-1-and-their-estimators-are-b-0-b-1-use-ols"><span>In SLR, 2 paras $\beta_0, \beta_1$, and their estimators are $b_0, b_1$. Use OLS:</span></a></h5><p>$$<br> min J(b_0, b_1) = min SSE=min\sum\limits_{i=1}^{n}[y_i - \hat{y_i}]<sup n="">2=min\sum\limits_{i=1}</sup>[y_i - b_0 -b_1x_i]^2<br> $$</p><p>Use partial derivatives, tl.hen get 2 estimators:</p><p>$$<br> b_0 = \bar{y} - b_1\bar{x}<br> $$</p><p>$$<br> b_1=\dfrac{n\bar{x}\bar{y}-\sum\limits_{i=1}<sup>{n}x_iy_i}{n\bar{x}</sup>2-\sum\limits_{i=1}<sup>{n}x_i</sup>2}<br> =\dfrac{\sum\limits_{i=1}<sup n="">{n}(x_i-\bar{x})y_i}{\sum\limits_{i=1}</sup>(x_i-\bar{x})^2}<br> =\dfrac{\sum\limits_{i=1}<sup n="">{n}(x_i-\bar{x})(y_i-\bar{y})}{\sum\limits_{i=1}</sup>(x_i-\bar{x})^2}<br> =\dfrac{S_\text{xy}}{S_\text{xx}}<br> $$</p><p>Because</p><p>$$<br> E(b_0)=\beta_0<br> $$</p><p>$$<br> E(b_1)=\beta_1<br> $$</p><p>$b_0, b_1$ are unbiased estimators.</p><p>$$<br> var(b_1)= \dfrac{\sigma<sup n="">2}{\sum\limits_{i=1}</sup>(x_i-\bar{x})^2}<br> $$</p><p>$$<br> var(b_0)=\sigma<sup>2(\dfrac{1}{n}+\dfrac{\bar{x}</sup>2}{\sum\limits_{i=1}<sup>{n}(x_i-\bar{x})</sup>2})<br> $$</p><p>$$<br> cov(b_0,b_1) = -\dfrac{\bar{x}\sigma^2}{S_\text{xx}}<br> $$</p><h3 id="_1-1-5-analysis-of-variance-anova" tabindex="-1"><a class="header-anchor" href="#_1-1-5-analysis-of-variance-anova"><span>1.1.5 Analysis of variance (ANOVA)</span></a></h3><ol><li>partition of digree of freedom for SLR.<br> equation: $y = \beta_0 + \beta_1x$ <ul><li>k = 2 for($\beta_0,\beta_1$)</li><li>n sample size</li></ul></li></ol><p>![[df.png]]</p><ol start="2"><li><p>Regression hypothesis</p><p>$$<br> H_0: \beta_1=0<br> $$</p><p>$$<br> H_1: \beta_1\neq0<br> $$</p><ul><li><p>$H_0 \text{ No regression relationship exists.}$</p></li><li><p>$H_1 \text{ Regression analyasis exists.}$<br> Then do <mark>F-test</mark>: test for the entire regression. Is the reg statistically significant?</p><p>$$<br> F_\text{k-1, n-k}=\dfrac{MSR}{MSE}=\dfrac{\frac{SSR}{k-1}}{\frac{SSE}{n-k}}<br> $$</p><p>where</p></li><li><p>k-1: df for reg</p></li><li><p>n-k: df for error<br><strong>Conclusion</strong>: Reject $H_0$ if $F_\text{CALC}&gt;F_\text{CV}$ . Regression analysis exists.<br> Note: F value can be used for ranking the importance of features. The bigger the F for a feature, the bigger the<br> SSR, in favor of $H_1$.</p></li></ul></li><li><p>Hypothesis for $\beta_1$</p><p>$$<br> H_0: \beta_1=0<br> $$</p><p>$$<br> H_1: \beta_1\neq0<br> $$</p><ul><li><p>$H_0 \text{ x has no impact on y.} E(y)=\beta_0$<br><mark>t-test</mark> is a test for only $\beta_1$. Is there an evidence that x contributes information in the prediction of<br> y?</p><p>$$<br> t_\text{n-k}=\dfrac{b_1}{\frac{\sqrt{MSE}}{\sqrt{\sum(x-\bar{x})^2}}}<br> $$</p><p><strong>Conclusion</strong>: Reject $H_0$ if $t_\text{CALC}&gt;t_\text{CV}$. x has impact on y.</p></li></ul></li><li><p>$R^2$ coefficient of determinate</p><p>$$<br> R<sup n="">2=\dfrac{SSR}{SST}=\dfrac{\sum\limits_{i=1}</sup>(\hat{y_i}-\bar{y})<sup n="">2}{\sum\limits_{i=1}</sup>(y_i-\bar{y})<br> ^2}=1-\dfrac{SSE}{SST}<br> $$</p><ul><li>$0&lt;R^2&lt;1$</li><li>$R^2$ means the proportion of variation in the response data that is explained by the <strong>model</strong>.</li><li>$R^2$ on its own cannot tell you anything about causation. (causaion means that a change in one variable causes a<br> change in another variable. correlation: there is a statistical association between variables)</li></ul></li></ol><h2 id="_1-2-generalized-linear-models-glm" tabindex="-1"><a class="header-anchor" href="#_1-2-generalized-linear-models-glm"><span>1.2 Generalized linear models (GLM)</span></a></h2><p>The differences between linear models and GLM.<br><strong>Standard linear model</strong>:</p><ul><li>systematic component:<br> $$<br> y = \beta_0+\beta_1x+\epsilon_i<br> $$</li><li>Link function is one. $\mu_i=x_i^T\beta$.</li><li>Random component: normal distribution $y_i \sim N(\mu_i,\sigma^2)$ residuals are normally distributed.</li><li>Estimators: least squares or maximum likelihood will give the same result<br> Not all situation can be considered as a normal distribution, large error.</li></ul><p><strong>GLM</strong>:</p><ul><li><p>systematic component:</p><p>$$<br> y = \beta_0+\beta_1x+\epsilon_i<br> $$</p></li><li><p>Link function is a function that delinearize the mathematical relationship between the predictors and the outcome. $g(\mu_i)=x_i^T\beta$ . The link function transforms the prediction part, everything except for the $\epsilon.$ You need<br> to decide this when doing analysis.</p></li><li><p>Random component: Residuals ars not normal, it might be comes from a poisson, a binomial, a gamma.</p></li><li><p>have to use maximum likelihood</p><p>![[Pasted image 20240803223049.png]]<br> [1] Types of GLM.</p></li></ul><p>two tpyes of varia: binomial.<br> skewed, positive discrete distribution: poisson. # times you go to a doctor.<br> skewed, positive continuous dist: gamma</p><h1 id="_2-time-series" tabindex="-1"><a class="header-anchor" href="#_2-time-series"><span>2 Time series</span></a></h1><h2 id="_2-1-time-series-data" tabindex="-1"><a class="header-anchor" href="#_2-1-time-series-data"><span>2.1 Time series data</span></a></h2><ol><li>assumption: observations at a certain point depend on previous observations in time.<br> decomposition:<br><strong>Time</strong> <strong>series</strong> = <strong>signal</strong>(forecasts extraplolate signal portion of model; trend/cycle and seasonal)<br> +<strong>noise</strong> (confidence intervals account for uncertainty; error/remainder/irregular) <ul><li>trend: classical: MA, morden way:</li><li>LOESS locally estimated scatterplot smoothing:non-parametric regression method that combines multiple regression<br> models in a k-nearest-neighbor-based meta-model. This technique is used to fit a smooth curve through points in a<br> scatterplot, especially when dealing with noisy data.<br> Steps: <ul><li><strong>Choose a point of interest</strong>.</li><li><strong>Identify the neighborhood</strong> around this point (based on the span).</li><li><strong>Fit a weighted least squares regression</strong> to the points in the neighborhood.</li><li><strong>Predict the value</strong> at the point of interest using the local regression model.</li><li><strong>Repeat</strong> the process for all points in the dataset.</li></ul></li></ul></li></ol><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> numpy </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> np</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> matplotlib.pyplot </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">as</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> plt</span></span>
<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> statsmodels.nonparametric.smoothers_lowess </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> lowess</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Example data</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">np.random.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">seed</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">x </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> np.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">linspace</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">10</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">100</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">y </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> np.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">sin</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x) </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">+</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> np.random.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">normal</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.5</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">100</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Apply LOESS</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">smoothed </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> lowess</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(y, x, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">frac</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0.2</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># frac is the span</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Plotting</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">scatter</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(x, y, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">label</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;Data&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">plot</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(smoothed[:, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], smoothed[:, </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">], </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">color</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;red&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">label</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&#39;LOESS Smoothed&#39;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">legend</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">plt.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">show</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">()</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="_2-2-models-for-time-series" tabindex="-1"><a class="header-anchor" href="#_2-2-models-for-time-series"><span>2.2 Models for time series</span></a></h3><p>![[Pasted image 20240805144951.png]]<br> [4]</p><ol><li><p>Exponential smoothing models<br> Apply a weighting scheme that decreases exponentially the further back in time we go. The larger the theta, the more<br> recent observation is emphasized.</p><p>$$<br> \hat{Y}<em>\text{t+1}=\theta Y_t+\theta(1-\theta)Y</em>\text{t-1}+\theta(1-\theta)<sup>2Y_\text{t-2}+\theta(1-\theta)</sup>3Y_<br> \text{t-3}+...<br> $$</p><p>$$<br> 0\le\theta\le1<br> $$</p><p>Simplify it, its prediction is like a horizontal line. So add trend and season terms in it. Holt winters exponential<br> smoothing forecast:</p><p>$$<br> \hat{Y}<em>\text{t+k}=L_t+kT_t+S</em>\text{t-p+k}<br> $$</p><p>$$<br> L_t=\theta Y_t + (1-\theta)L_\text{t-1}<br> $$</p><p>$$<br> T_t=\gamma(L_t-L_\text{t-1})+(1-\gamma)T_\text{t-1}<br> $$</p><p>$$<br> S_t=\delta(Y_t-L_t)+(1-\delta)S_\text{t-p}<br> $$</p></li><li><p>consistency of distribution: can&#39;t have independece, but still want some consistency. Distribution depends only on<br> difference in time, not location in time. same width(any size) of time, same distribution-strong stationarity.<br> mean, var, autocorrelation depends only on difference in time-weak stationarity.<br> Strong stationarity does not imply the weak one. Weak needs finite variance, strong does not.</p></li><li><p><strong>weak stationarity helps build stationary classes of models: MA...ARIMA</strong><br> not sationary: no consistent mean and var.<br> 4.1 shifts in mean(not stationary):<br> ![[Pasted image 20240804145903.png]]<br> [4]<br> common solution: differencing:</p><ul><li>trend: look at the difference between the current point and previous one $Y_t-Y_\text{t-1}$</li><li>season: look at the difference between the current point and the same point in the previous season $Y_t-Y_\text{t-S}$<br> 4.2 shifts in variance:</li><li>ignore when most models only model the mean</li><li>model the lack of consistency in var: ARCH/GARCH</li></ul></li><li><p>autoregressive models</p><ul><li><p>forecast a series based on the past values in the series-lagsAR(1)</p><p>$$<br> Y_t = \omega + \phi Y_\text{t-1}+e_t<br> $$</p><p>target $Y_t$ , Lagged Target $Y_\text{t-1}$, $e_t$ error.</p></li></ul><p>The recursion in time goes back until the beginngn of the series-long memory models. if $|\phi|&lt;1$ shocks happens long<br> ago has little effect at the present.</p><p>You can also has n lags AR(n).</p></li><li><p>Moving average model. Forecast a series based solely on the past errors-error lags. short memory models</p><p>$$<br> Y_t = \omega + \theta e_\text{t-1} + e_t<br> $$</p></li></ol><p>![[Pasted image 20240804224532.png]]</p><p>MA(n)</p><p>$$<br> Y_\text{t-1} = \omega + \theta e_\text{t-2} + e_\text{t-1}<br> $$</p><p>$$<br> Y_\text{t} = \omega + \theta e_\text{t-1} + e_\text{t}<br> $$</p><p>$$<br> Y_\text{t+1} = \omega + \theta e_\text{t} + e_\text{t+1}<br> $$</p><p>No more $e_\text{t-1}$</p><ol start="6"><li><p>ARIMA</p><ol><li><p>ARIMA<br> first, make your data stationary (typically done throug differencing).<br> Distribution depends only on difference in time.<br> AR, integrated, MA.</p><p>$$<br> Y_t=\omega+\phi_1Y_\text{t-1}+...+\phi_pY_\text{t-p}+\theta_1e_\text{t-1}+...+\theta_qe_\text{t-q}+e_t<br> $$</p><p>Deciding how many p&#39;s and q&#39;s. 2 techniques:</p><ul><li>Plotting patterns in correlation</li><li>Automatic selection techniques: MINIC, SCAN, ESACF</li></ul><p>ARIMA(d,p,q)=ARIMA(#ARterms, # first differences, # Aterms)</p><p>$$<br> ARIMA(1,1,1)<br> $$</p><p>$$<br> Y_t-Y_\text{t-1}=W_t<br> $$</p><p>$$<br> W_t=\omega+\phi_1W_\text{t-1}+\theta_1e_\text{t-1}+e_t<br> $$</p></li><li><p>seasonal ARIMA: when data are not stationary.<br> ARIMA(p,d,q)(P,D,Q)s</p><ul><li>P: # seasonal AR terms</li><li>D: # seasonal differences</li><li>Q: # seasonal MA terms</li><li>s: length of season</li></ul><p>$$<br> ARIMA(1,0,1)(2,1,0)_\text{12}<br> $$</p><p>$$<br> Y_t-Y_\text{t-12}=W_t<br> $$</p><p>$$<br> W_t=\omega+\phi_1W_\text{t-1}+\phi_2W_\text{t-12}+\phi_3W_\text{t-24}+\theta_1e_\text{t-1}+e_t<br> $$</p></li></ol></li><li><p>Neural network time series models<br> input: # Number of autoregressive lags(AR lags): explore with correlation plots or aotomatic selection tecniques.<br> seasonal data: typically include all lags up through one season unless correlation plots say you only need specific<br> ones.<br> STILL WANT TO MAKE DATA STATIONARY FIRST.</p></li><li><p>Prophet model<br><strong>Time series</strong> = <strong>signal</strong>(forecasts extraplolate signal portion of model; trend/cycle, seasonal, holiday)<br> +<strong>noise</strong> (confidence intervals account for uncertainty; error/remainder/irregular)</p><ol><li>trend lines with knots, logorithm trend...</li><li>seasonal: fourier transformation</li><li>holiday-point(pulse) intervention</li></ol></li><li><p>Vector autoregressive (VAR) model:</p><ol><li>model multiple time series at one time.</li><li>multivariate regression is not multiple regression</li><li>trying to predict multiple target variable at the same time</li><li>when estimating 1 target variable, common: ARMA&gt;AR</li><li>when .... multiple ... , common: VAR &gt; VARMA<br> ![[Pasted image 20240805151510.png]]<br> [5]</li></ol></li><li><p>Bayesian autoregressive models</p><p>$$<br> Y_t=\alpha_0+\alpha_1Y_\text{t-1}+...+\alpha_pY_\text{t-q}+e_t<br> $$</p></li><li><p>ARCH, GARCH</p><ol><li><p>unconditional variance</p><p>$$<br> Var(x)=\sigma<sup n="">2=\dfrac{1}{n-1}\sum\limits_{i=1}</sup>(x_i-\bar{x}<sup>2)=E(x-E(x))</sup>2<br> $$</p></li><li><p>conditional variance: the measure of uncertainty about a variable given a set of information<br> Heteroscedasticity-variance depends on external factors.(variance are changing)</p><p>$$<br> Var(x|I)=\sigma_\text{cond}<sup>2=E(x-E(x|I))</sup>2<br> $$</p><p>In cross-sectional data, heteroscedasticity: avoid<br> In time series data especially in finance: we desire to model it. 建模return 更有规律。</p></li><li><p>Autoregressive conditional heteroscedasticity. Trying to account for time dependency and &quot;clustering&quot; of<br> volatility.<br> Volatility tommorow: $\sigma_\text{t+1}^2$<br> Actual today: $r_t^2$</p><p>$$<br> \sigma_\text{t+1}<sup>2=\alpha_0+\alpha_1r_t</sup>2<br> $$</p><p>why? Use squared returns to estimate a daily volatility:</p><p>$$<br> \sigma_\text{t}<sup t="">2=\frac{1}{t}\sum\limits_{i=1}</sup>(r_t-\bar{r})^2<br> =\frac{1}{t}\sum\limits_{i=1}<sup>{t}(r_t-0)</sup>2<br> =\frac{1}{1}\sum\limits_{i=1}<sup>{t}(r_t)</sup>2<br> =r_t^2<br> $$</p><ul><li>volatility tomorrow: $\sigma_\text{t+1}^2$</li><li>actual today: $\alpha_1r_t^2$<br> ARCH(n) uses multiple lags in the past to model the volatility.</li></ul></li><li><p>generalized ARCH (GARCH).</p><p>$$<br> \sigma_\text{t+1}<sup>2=\alpha_0+\alpha_1r_t</sup>2+\beta_1\hat{\sigma_t}^2<br> $$</p><ul><li>volatility tomorrow: $\sigma_\text{t+1}^2$<br> Real world data typically needs one of each:</li><li>actual today: $\alpha_1r_t^2$</li><li>forecasted today:$\beta_1\hat{\sigma_t}^2$</li></ul></li></ol></li><li><p>ECM<br> An<strong>error correction model</strong>(<strong>ECM</strong>) belongs to a category of multiple <a href="https://en.wikipedia.org/wiki/Time_series" title="Time series" target="_blank" rel="noopener noreferrer">time series</a>models most commonly used for data<br> where the underlying variables have a long-run common stochastic trend, also known<br> as <a href="https://en.wikipedia.org/wiki/Cointegration" title="Cointegration" target="_blank" rel="noopener noreferrer">cointegration</a>.[3]</p></li></ol><h3 id="_2-3-model-evaluation" tabindex="-1"><a class="header-anchor" href="#_2-3-model-evaluation"><span>2.3 Model evaluation</span></a></h3><ol><li><p>Prediction<br> MAPE. mean absolute percentage error</p><p>$$<br> MAPE=\frac{1}{n}\sum\limits_{t=1}^{n}|\dfrac{Y_t-\hat{Y_t}}{Y_t}|<br> $$</p><p>sMAPE. symmetric MAPE</p><p>$$<br> sMAPE=\frac{1}{n}\sum\limits_{t=1}^{n}\dfrac{|Y_t-\hat{Y_t}|}{(|Y_t|+|\hat{Y_t}|)}<br> $$</p></li><li><p>validation: rolling hold-out samples: 连续的按顺序逐步下扩张自己的训练集，测试集长度不变紧跟训练集。一次完成后，记录误差，模型基于此次训练集更新。然后继续向下扩张特定数量的训练集。</p></li></ol><h1 id="_3-nonparametric-regression" tabindex="-1"><a class="header-anchor" href="#_3-nonparametric-regression"><span>3 Nonparametric Regression</span></a></h1><p>Splines, Kernel, Locally Weighted Regression<br> Most of tools in classical statistics are parametrics, they rely on assumptions about the underlying distribution of the data being studied.Techniques like least squares regression (which assumes normally distributed residuals) are parametric.Non-parametric machine learning algorithms do not rely on assumptions about the shape of the underlying data to work.</p><h1 id="_4-data-exploration" tabindex="-1"><a class="header-anchor" href="#_4-data-exploration"><span>4 Data exploration</span></a></h1><p><a href="https://www.geeksforgeeks.org/density-plots-with-pandas-in-python/" target="_blank" rel="noopener noreferrer">https://www.geeksforgeeks.org/density-plots-with-pandas-in-python/</a></p><ol><li>density</li><li>estimation</li><li>normality</li><li>test</li><li>monte carla copulas</li></ol><h1 id="_5-data-cleaning" tabindex="-1"><a class="header-anchor" href="#_5-data-cleaning"><span>5 Data Cleaning</span></a></h1><h3 id="references" tabindex="-1"><a class="header-anchor" href="#references"><span>References:</span></a></h3><p>[1]<a href="https://www.youtube.com/watch?v=SqN-qlQOM5A" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=SqN-qlQOM5A</a><br> [2]<a href="https://www.youtube.com/watch?v=hAD5vVz07ZA&amp;list=PLjwX9KFWtvNnOc4HtsvaDf1XYG3O5bv5s&amp;index=3" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=hAD5vVz07ZA&amp;list=PLjwX9KFWtvNnOc4HtsvaDf1XYG3O5bv5s&amp;index=3</a><br> [3]<a href="https://en.wikipedia.org/wiki/Error_correction_model" target="_blank" rel="noopener noreferrer">https://en.wikipedia.org/wiki/Error_correction_model</a><br> [4]<a href="https://www.youtube.com/watch?v=R3Y0KQ-RkCE&amp;list=PLjwX9KFWtvNnOc4HtsvaDf1XYG3O5bv5s&amp;index=9" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=R3Y0KQ-RkCE&amp;list=PLjwX9KFWtvNnOc4HtsvaDf1XYG3O5bv5s&amp;index=9</a><br> [5]<a href="https://www.youtube.com/watch?v=0-FKPJ5KxSo&amp;list=PLjwX9KFWtvNnOc4HtsvaDf1XYG3O5bv5s&amp;index=11" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=0-FKPJ5KxSo&amp;list=PLjwX9KFWtvNnOc4HtsvaDf1XYG3O5bv5s&amp;index=11</a></p></div><!----><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/vuepress-theme-hope/vuepress-theme-hope/edit/main/src/posts/Fin/Statistics.md" aria-label="Edit this page on GitHub" rel="noopener noreferrer" target="_blank" iconsizing="both"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->Edit this page on GitHub<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">Last update: </span><span class="vp-meta-info" data-allow-mismatch="text">3/22/2025, 9:55:29 PM</span></div><div class="contributors"><span class="vp-meta-label">Contributors: </span><!--[--><!--[--><span class="vp-meta-info" title="email: liuyuhailiuyuhao@gmail.com">Krigo-Liu</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/posts/Fin/BF.html" aria-label="BFR-Microeconomics" iconsizing="both"><div class="hint"><span class="arrow start"></span>Prev</div><div class="link"><iconify-icon class="vp-icon" icon="fa6-solid:file" height="1em" sizing="height"></iconify-icon>BFR-Microeconomics</div></a><a class="route-link auto-link next" href="/posts/Fin/BacktestEva.html" aria-label="BacktestEva" iconsizing="both"><div class="hint">Next<span class="arrow end"></span></div><div class="link">BacktestEva<iconify-icon class="vp-icon" icon="fa6-solid:file" height="1em" sizing="height"></iconify-icon></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><div class="vp-footer">What is the meaning of data?</div><div class="vp-copyright">无版权</div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-HjLdIzEb.js" defer></script>
  </body>
</html>
