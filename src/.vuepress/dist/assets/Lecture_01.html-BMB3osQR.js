import{_ as o}from"./plugin-vue_export-helper-DlAUqK2U.js";import{o as i,c as n,a as e,b as t,e as r}from"./app-sSjdaIB9.js";const a={},l=e("h2",{id:"course-main-theme",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#course-main-theme"},[e("span",null,"Course Main Theme")])],-1),s=r("<li>Designing and writing parallel programs —— scale! (规模) <ul><li>Parallel thing <ol><li><strong>Decomposing</strong>(分解) the work into pieces that can safely be performed in parallel</li><li>Assigning work to processors</li><li><strong>Managing</strong> communication/synchronization(同步) between the processors so that it does not limit <strong>speedup</strong></li></ol></li></ul></li><li>Parallel computer hardware implemtation: how parallel computers work <ul><li>Mechanisms(机制) used to implement abstractions effeciently <ol><li>Performance(性能) characteristics of implementations</li><li><strong>Design trade-offs: performance vs. convenience vs. cost</strong></li></ol></li></ul></li>",2),c={class:"MathJax",jax:"SVG",style:{position:"relative"}},m={style:{"vertical-align":"-0.486ex"},xmlns:"http://www.w3.org/2000/svg",width:"1.76ex",height:"2.106ex",role:"img",focusable:"false",viewBox:"0 -716 778 931","aria-hidden":"true"},p=e("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[e("g",{"data-mml-node":"math"},[e("g",{"data-mml-node":"mo"},[e("path",{"data-c":"2260",d:"M166 -215T159 -215T147 -212T141 -204T139 -197Q139 -190 144 -183L306 133H70Q56 140 56 153Q56 168 72 173H327L406 327H72Q56 332 56 347Q56 360 70 367H426Q597 702 602 707Q605 716 618 716Q625 716 630 712T636 703T638 696Q638 692 471 367H707Q722 359 722 347Q722 336 708 328L451 327L371 173H708Q722 163 722 153Q722 140 707 133H351Q175 -210 170 -212Q166 -215 159 -215Z"})])])],-1),g=[p],h=e("mjx-assistive-mml",{unselectable:"on",display:"inline"},[e("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[e("mo",null,"≠")])],-1),u=e("li",null,"Your program runs faster on a parallel computer, it deos not mean it is using the hardware efficiently.",-1);function d(f,y){return i(),n("div",null,[l,e("ol",null,[s,e("li",null,[t("Thinking about efficiency "),e("ul",null,[e("li",null,[t("Fast "),e("mjx-container",c,[(i(),n("svg",m,g)),h]),t(" Efficient")]),u])])])])}const C=o(a,[["render",d],["__file","Lecture_01.html.vue"]]),T=JSON.parse(`{"path":"/posts/CS/Parallel%20Computer%20Architectyre%20and%20Programming/Lecture_01.html","title":"CMU 15-418 Lecture 01","lang":"zh-CN","frontmatter":{"title":"CMU 15-418 Lecture 01","icon":"file","order":3,"author":"Krigo","category":["CS"],"tag":["CS","Parallel Computing","Coding"],"footer":"Thank's myself until I find a jinx to ask questions. haha","copyrigh":"无版权","description":"Course Main Theme Designing and writing parallel programs —— scale! (规模) Parallel thing Decomposing(分解) the work into pieces that can safely be performed in parallel Assigning w...","head":[["meta",{"property":"og:url","content":"https://mister-hope.github.io/blog/posts/CS/Parallel%20Computer%20Architectyre%20and%20Programming/Lecture_01.html"}],["meta",{"property":"og:site_name","content":"Krigo's 博客"}],["meta",{"property":"og:title","content":"CMU 15-418 Lecture 01"}],["meta",{"property":"og:description","content":"Course Main Theme Designing and writing parallel programs —— scale! (规模) Parallel thing Decomposing(分解) the work into pieces that can safely be performed in parallel Assigning w..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-03-18T07:30:24.000Z"}],["meta",{"property":"article:author","content":"Krigo"}],["meta",{"property":"article:tag","content":"CS"}],["meta",{"property":"article:tag","content":"Parallel Computing"}],["meta",{"property":"article:tag","content":"Coding"}],["meta",{"property":"article:modified_time","content":"2024-03-18T07:30:24.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"CMU 15-418 Lecture 01\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-03-18T07:30:24.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Krigo\\"}]}"]]},"headers":[{"level":2,"title":"Course Main Theme","slug":"course-main-theme","link":"#course-main-theme","children":[]}],"git":{"createdTime":1710747024000,"updatedTime":1710747024000,"contributors":[{"name":"Krigo-Liu","email":"liuyuhailiuyuhao@gmail.com","commits":1}]},"readingTime":{"minutes":0.48,"words":143},"filePathRelative":"posts/CS/Parallel Computer Architectyre and Programming/Lecture_01.md","localizedDate":"2024年3月18日","excerpt":"<h2>Course Main Theme</h2>\\n<ol>\\n<li>Designing and writing parallel programs —— scale! (规模)\\n<ul>\\n<li>Parallel thing\\n<ol>\\n<li><strong>Decomposing</strong>(分解) the work into pieces that can safely be performed in parallel</li>\\n<li>Assigning work to processors</li>\\n<li><strong>Managing</strong> communication/synchronization(同步) between the processors so that it does not limit <strong>speedup</strong></li>\\n</ol>\\n</li>\\n</ul>\\n</li>\\n<li>Parallel computer hardware implemtation: how parallel computers work\\n<ul>\\n<li>Mechanisms(机制) used to implement abstractions effeciently\\n<ol>\\n<li>Performance(性能) characteristics of implementations</li>\\n<li><strong>Design trade-offs: performance vs. convenience vs. cost</strong></li>\\n</ol>\\n</li>\\n</ul>\\n</li>\\n<li>Thinking about efficiency\\n<ul>\\n<li>Fast  Efficient</li>\\n<li>Your program runs faster on a parallel computer, it deos not mean it is using the hardware efficiently.</li>\\n</ul>\\n</li>\\n</ol>","autoDesc":true}`);export{C as comp,T as data};
